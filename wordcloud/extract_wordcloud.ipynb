{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ceb2b1-132a-46bc-bbdb-5d509c7371a6",
   "metadata": {},
   "source": [
    "# Bibliotecas e preparação do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eea7de8-52c3-4752-b991-c9e70cfbd841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import uuid\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pathlib import Path\n",
    "from unicodedata import normalize\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e9752d-9803-4935-8478-a50487f46d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time format for json result files\n",
    "RESULT_TS_FORMAT = '%Y%m%d%H%M%S%f'\n",
    "# time format for wordcloud files\n",
    "OUTPUT_TS_FORMAT = '%d/%m/%Y %H:%M:%S'\n",
    "# sites to ignore results\n",
    "BLACK_LISTED_SITES = ['gov.br', 'fccid.io', 'wer-hat-angerufen.info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd8985d-deb4-41d7-b81f-5dfb5a9b6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_site(url):\n",
    "    return '.'.join(urlparse(url).netloc.split('.')[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e36f6f-af97-4972-8924-d0aa9b56dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_black_listed_site(url,black_listed_sites=BLACK_LISTED_SITES):\n",
    "    for site in black_listed_sites:\n",
    "        if site in url:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f96e17ba-2f31-41ae-bdeb-455d91eb411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(doc,normalize_words=False):\n",
    "\n",
    "    stop_words = stopwords.words('portuguese')\n",
    "    stop_words.extend(stopwords.words('english'))\n",
    "    stop_words.extend(list(string.punctuation))\n",
    "\n",
    "    # stopwords específicas do domínio\n",
    "    stop_words.extend(['cm', 'feature', 'features', 'informações', 'itens', 'leve', 'list', 'nulo', 'package', \n",
    "                       'pacote', 'pacotes', 'recurso', 'tamanho', 'ver', 'anatel', 'laranja', '.', '...',\n",
    "                       'complementares', 'peça'])\n",
    "\n",
    "    if normalize_words:\n",
    "        doc = doc.lower()\n",
    "        doc = normalize('NFKD', doc).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "    # CountVectorizer token pattern\n",
    "    pattern = r'\\b\\w\\w+\\b'\n",
    "    tokens = [token for token in re.findall(pattern,doc) if token.lower() not in stop_words]\n",
    "    # remove number-only tokens\n",
    "    tokens = [token for token in tokens if not re.match('\\d+',token)]\n",
    "\n",
    "    # NLTK tokenizer\n",
    "    # tokens = [token for token in word_tokenize(doc) if token.lower() not in stop_words]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c9302be-7322-4f53-abae-598b37ab19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file should be a Path object\n",
    "def parse_result_file(file, nWords=25):\n",
    "\n",
    "    search_date, search_engine, search_term, _ = re.split('[_.]',file.name)\n",
    "    search_site = None\n",
    "    \n",
    "    with open(file) as f:\n",
    "        results = json.load(f)\n",
    "        lines = []\n",
    "        if search_engine == 'GOOGLE':\n",
    "            # results without items in keys are empty\n",
    "            if 'items' in results.keys():\n",
    "                for item in results['items']:\n",
    "                    search_site = item['displayLink']\n",
    "                    if is_black_listed_site(search_site):\n",
    "                        continue\n",
    "                    else:\n",
    "                        search_site = parse_site(search_site)\n",
    "                        lines.append(item['title'])\n",
    "                        if 'snippet' in item.keys():\n",
    "                            lines.append(item['snippet'])\n",
    "                        \n",
    "        elif search_engine == 'BING':\n",
    "            # results without webPages in keys are empty\n",
    "            if 'webPages' in results.keys():\n",
    "                for item in results['webPages']['value'][:10]:\n",
    "                    search_site = item['url']\n",
    "                    if is_black_listed_site(search_site):\n",
    "                        continue\n",
    "                    else:\n",
    "                        search_site = parse_site(search_site)\n",
    "                        lines.append(item['name'])\n",
    "                        if 'snippet' in item.keys():\n",
    "                            lines.append(item['snippet'])\n",
    "                    \n",
    "        if len(lines) >= 1:\n",
    "            words = tokenizer(' '.join(lines))\n",
    "            words_conter = Counter(words)\n",
    "            wordCloud_dict = {key:value for key,value in words_conter.most_common(nWords)}\n",
    "            wordCloud_json = json.dumps(wordCloud_dict, ensure_ascii=False)\n",
    "        else:\n",
    "            wordCloud_json = ''\n",
    "        \n",
    "        wourdCloudInfo_dict = {\n",
    "            'metaData': {\n",
    "                'Version': 1,\n",
    "                'Source': search_engine,\n",
    "                'Mode': 'API',\n",
    "                'Fields': ['Name', 'Snippet'],\n",
    "                'nWords': nWords\n",
    "            },\n",
    "            'searchedWord': search_term,\n",
    "            'cloudOfWords': wordCloud_json\n",
    "        }\n",
    "    \n",
    "        wourdCloudInfo_json = json.dumps(wourdCloudInfo_dict, ensure_ascii=False)\n",
    "    \n",
    "        return {'ID': str(uuid.uuid4()),\n",
    "                'DataHora': datetime.strptime(search_date,RESULT_TS_FORMAT).strftime(OUTPUT_TS_FORMAT),\n",
    "                'Computador': os.environ['COMPUTERNAME'],\n",
    "                'Usuário': 'E!', \n",
    "                'Homologação': f'{search_term[:5]}-{search_term[5:7]}-{search_term[-5:]}', \n",
    "                'Atributo': 'WordCloud',\n",
    "                'Valor': wourdCloudInfo_json,               \n",
    "                'Buscadora': search_engine}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563f7d6-546f-4f78-afc4-86230d735553",
   "metadata": {},
   "source": [
    "# Pesquisa\n",
    "\n",
    "Nessa etapa serão feitas as pesquisas no Bing e no Google. Os resultados de cada consulta serão armazenados em um arquivo .json contendo a resposta bruta da consulta. \n",
    "\n",
    "Os arquivos serão armazenados na pasta *datasets/searchresults* com o seguinte formato de nome: `{data/hora da consulta}\\_{mecanismo de busca}\\_{nº do certificado de homologação}.json`, onde:\n",
    "- data/hora da consulta: data e hora que a consulta foi realizada, no formato `%Y%m%d%H%M%S%f`\n",
    "- mecanismo de busca: `GOOGLE` ou `BING`\n",
    "- nº do certificado de homologação: número do certificado de homologação (apenas números)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b6f67-b3a3-41b5-8abf-40c955e8a941",
   "metadata": {},
   "source": [
    "# Tratamento dos dados\n",
    "\n",
    "Nessa etapa cada arquivo será lido e dele extraído o nome ou título e o resumo (*snippet*) da resposta para consolidar e criar a wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c959e43b-8b9d-4a28-8bb8-eba0dddec60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DataHora</th>\n",
       "      <th>Computador</th>\n",
       "      <th>Usuário</th>\n",
       "      <th>Homologação</th>\n",
       "      <th>Atributo</th>\n",
       "      <th>Valor</th>\n",
       "      <th>Buscadora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28f39a79-14a5-41f2-a96b-4879027ea5d6</td>\n",
       "      <td>23/02/2024 15:01:29</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>03724-22-14637</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e737eebd-d1d8-46ee-b8af-c2635000c15b</td>\n",
       "      <td>23/02/2024 15:01:30</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>02035-19-01516</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e6915a1b-aba8-405c-a660-5af517bf36dd</td>\n",
       "      <td>23/02/2024 15:01:31</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>02018-19-01516</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1fc341fc-14c5-410b-b4ff-c85e50f6d990</td>\n",
       "      <td>23/02/2024 15:01:31</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>06618-19-01516</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45001f65-eefe-4bca-a2ec-7c53282cb8dd</td>\n",
       "      <td>23/02/2024 15:01:32</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>12303-20-01516</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5c01a800-74a8-4899-b5ba-f75aed6d6a11</td>\n",
       "      <td>23/02/2024 15:01:32</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>03744-21-13015</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cf50dec7-971e-4695-9c97-d20b9e752945</td>\n",
       "      <td>23/02/2024 15:01:33</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>10746-20-11685</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>df5a6fa3-de27-4e07-b535-5160b660dafe</td>\n",
       "      <td>23/02/2024 15:01:33</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>13263-20-11685</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>194a8ec9-60d0-4ddd-9d16-4184eac589cd</td>\n",
       "      <td>23/02/2024 15:01:34</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>06776-22-14103</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43790c04-ee01-4d1f-9916-60566f22c328</td>\n",
       "      <td>23/02/2024 15:01:34</td>\n",
       "      <td>ES6927559DTL</td>\n",
       "      <td>E!</td>\n",
       "      <td>13637-21-14103</td>\n",
       "      <td>WordCloud</td>\n",
       "      <td>{\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...</td>\n",
       "      <td>GOOGLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID             DataHora    Computador  \\\n",
       "0  28f39a79-14a5-41f2-a96b-4879027ea5d6  23/02/2024 15:01:29  ES6927559DTL   \n",
       "1  e737eebd-d1d8-46ee-b8af-c2635000c15b  23/02/2024 15:01:30  ES6927559DTL   \n",
       "2  e6915a1b-aba8-405c-a660-5af517bf36dd  23/02/2024 15:01:31  ES6927559DTL   \n",
       "3  1fc341fc-14c5-410b-b4ff-c85e50f6d990  23/02/2024 15:01:31  ES6927559DTL   \n",
       "4  45001f65-eefe-4bca-a2ec-7c53282cb8dd  23/02/2024 15:01:32  ES6927559DTL   \n",
       "5  5c01a800-74a8-4899-b5ba-f75aed6d6a11  23/02/2024 15:01:32  ES6927559DTL   \n",
       "6  cf50dec7-971e-4695-9c97-d20b9e752945  23/02/2024 15:01:33  ES6927559DTL   \n",
       "7  df5a6fa3-de27-4e07-b535-5160b660dafe  23/02/2024 15:01:33  ES6927559DTL   \n",
       "8  194a8ec9-60d0-4ddd-9d16-4184eac589cd  23/02/2024 15:01:34  ES6927559DTL   \n",
       "9  43790c04-ee01-4d1f-9916-60566f22c328  23/02/2024 15:01:34  ES6927559DTL   \n",
       "\n",
       "  Usuário     Homologação   Atributo  \\\n",
       "0      E!  03724-22-14637  WordCloud   \n",
       "1      E!  02035-19-01516  WordCloud   \n",
       "2      E!  02018-19-01516  WordCloud   \n",
       "3      E!  06618-19-01516  WordCloud   \n",
       "4      E!  12303-20-01516  WordCloud   \n",
       "5      E!  03744-21-13015  WordCloud   \n",
       "6      E!  10746-20-11685  WordCloud   \n",
       "7      E!  13263-20-11685  WordCloud   \n",
       "8      E!  06776-22-14103  WordCloud   \n",
       "9      E!  13637-21-14103  WordCloud   \n",
       "\n",
       "                                               Valor Buscadora  \n",
       "0  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  \n",
       "1  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  \n",
       "2  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  \n",
       "3  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  \n",
       "4  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  \n",
       "5  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  \n",
       "6  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  \n",
       "7  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  \n",
       "8  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  \n",
       "9  {\"metaData\": {\"Version\": 1, \"Source\": \"GOOGLE\"...    GOOGLE  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_folder = Path('datasets/searchresults')\n",
    "results_files = [file for file in results_folder.glob('*.json')]\n",
    "df = pd.DataFrame([parse_result_file(file) for file in results_files[:10]])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
